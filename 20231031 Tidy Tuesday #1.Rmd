---
title: "20231031 Tidy Tuesday - Spooky Article author fact checked df"
output: html_document
date: "2023-10-31"
---
# Description of Dataset
Snope Articles written by authors who fact-check various urban legends and stories and give them various ratings, within the dataset also includes a central claim, which is a summary sentence of the article. This was used to text-mine keywords to generate the word cloud and associate it with the rating column. 

# My thought process for this dataset
I initially tried to text-mine the claims vector for geographical locations and tie them to a coordinate system using packages like map and building out a series using the dates published vector and with a toggle function based on the rating vector. However, this proved to be difficult, the text-mining showed not only states but counties and cities. Hence, I decided to represent filtered data based on ratings in a word cloud, with hopes of gaining insights into what types of articles tended to be horror legends and what they typically include. 

```{r install packages}
install.packages(c("wordcloud2", "tm", "readr", "dplyr", "htmlwidgets"))
```

```{r loading libraries}
library(wordcloud2)
library(tm)
library(readr)
library(dplyr)
library(htmlwidgets)
```

```{r data-prep}
# Load Dataset, Filter, and Convert Claims into a Corpus
horror_articles <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-10-31/horror_articles.csv')
horror_articles <- horror_articles %>% filter(rating == "legend")

horror_articles.corpus = Corpus(VectorSource(horror_articles$claim))
horror_articles.corpus <- horror_articles.corpus %>%
  tm_map(removeNumbers) %>%
  tm_map(removePunctuation) %>%
  tm_map(stripWhitespace) %>%
  tm_map(content_transformer(tolower)) %>%
  tm_map(removeWords, stopwords("english")) %>%
  tm_map(removeWords, stopwords("SMART"))

tdm = TermDocumentMatrix(horror_articles.corpus) %>%
  as.matrix()
words = sort(rowSums(tdm), decreasing = TRUE)
df = data.frame(word = names(words), freq = words)

# This line removes frequently appearing short word/determiners
df <- df %>% filter(nchar(as.character(word)) > 2, word != "donâ€™")
```

```{r wordcloud}
word_cloud <- wordcloud2(df, fontFamily="Times New Roman")
word_cloud
```

```{r view-data}
# View Top Words
head(df, n = 10)
nrow(horror_articles)
```


